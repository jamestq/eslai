{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62d10a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf8398b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"dataset/train.tsv\"\n",
    "df = pd.read_csv(dataset_path, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e169b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all columns except 'path', 'sentence', 'age', 'gender', 'accents'\n",
    "df = df[['path', 'sentence', 'age', 'gender', 'accents']]\n",
    "# Filter out rows where 'accents' is NaN or empty\n",
    "df_filtered = df[df['accents'].notna() & (df['accents'] != '') & df['gender'].notna() & df['age'].notna()]\n",
    "print(df_filtered.head())\n",
    "print(df_filtered.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bc34b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chart the distribution of accents in a pie chart\n",
    "# Create a function to display the actual counts\n",
    "def make_autopct(values):\n",
    "    def my_autopct(pct):\n",
    "        total = sum(values)\n",
    "        val = int(round(pct*total/100.0))\n",
    "        return '{v:d}'.format(v=val)\n",
    "    return my_autopct\n",
    "\n",
    "top_values = 10\n",
    "\n",
    "# Create a figure with 2 rows and 2 columns of subplots\n",
    "fig, axs = plt.subplots(1,3, figsize=(30,20))\n",
    "\n",
    "# Accents distribution\n",
    "accents_value_counts = df_filtered['accents'].value_counts()\n",
    "axs[0].pie(accents_value_counts[0:top_values],              \n",
    "             autopct=make_autopct(accents_value_counts[0:top_values]), \n",
    "             startangle=120)\n",
    "axs[0].legend(accents_value_counts.index[0:top_values], loc='lower right', bbox_to_anchor=(-0.1, 0))\n",
    "axs[0].set_title(\"Distribution of Accents\")\n",
    "\n",
    "# Gender distribution\n",
    "gender_value_counts = df_filtered['gender'].value_counts()\n",
    "axs[1].pie(gender_value_counts[0:top_values],              \n",
    "              autopct=make_autopct(gender_value_counts[0:top_values]),\n",
    "              startangle=30)\n",
    "axs[1].legend(gender_value_counts.index[0:top_values], loc='lower center', bbox_to_anchor=(-0.1, 0))\n",
    "axs[1].set_title(\"Distribution of Gender\")\n",
    "\n",
    "# Age distribution\n",
    "age_value_counts = df_filtered['age'].value_counts()\n",
    "axs[2].pie(age_value_counts[0:top_values],              \n",
    "              autopct=make_autopct(age_value_counts[0:top_values]),\n",
    "              startangle=30)\n",
    "axs[2].legend(age_value_counts.index[0:top_values], loc='lower center', bbox_to_anchor=(-0.1, 0))\n",
    "axs[2].set_title(\"Distribution of Age\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948a2b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert a new row into df_filtered\n",
    "# new_row = pd.DataFrame({\n",
    "#   \"path\": [\"sample.wav\"],\n",
    "#   \"sentence\": [\"Please call Stella, ask her to bring these things to the store\"],\n",
    "#   \"age\": [\"twenties\"],\n",
    "#   \"gender\": [\"male_masculine\"],\n",
    "#   \"accents\": [\"England English\"]\n",
    "# })\n",
    "# df_filtered = pd.concat([new_row, df_filtered.head(10)], ignore_index=True)\n",
    "# df_filtered.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfe5ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"dataset/train_clean.csv\"\n",
    "df_filtered.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe817c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Audio\n",
    "# Load the dataset and save it in a format compatible with Hugging Face datasets\n",
    "input_path = \"dataset/train_clean.csv\"\n",
    "dataset = load_dataset(\"csv\", data_files=input_path, split=\"train\")\n",
    "dataset = dataset.cast_column(\"path\", Audio(sampling_rate=16000))\n",
    "\n",
    "def load_audio(dataset):\n",
    "    return {\"path\": [x['path'] for x in dataset['path']]}\n",
    "\n",
    "dataset = dataset.map(load_audio, batched=True)\n",
    "dataset.save_to_disk(\"dataset/train_clean\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venvs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
