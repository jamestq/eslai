{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries, loading and transforming data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T19:32:57.487527Z",
     "iopub.status.busy": "2023-12-18T19:32:57.486746Z",
     "iopub.status.idle": "2023-12-18T19:36:11.539613Z",
     "shell.execute_reply": "2023-12-18T19:36:11.538466Z",
     "shell.execute_reply.started": "2023-12-18T19:32:57.487494Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Install the 'evaluate' library with the specified version (4.28.1) quietly (-q).\n",
    "!pip install -q evaluate transformers==4.28.1\n",
    "\n",
    "# Upgrade the 'datasets' library to the latest version quietly (-q).\n",
    "!pip install -U -q datasets\n",
    "\n",
    "# Install the 'torchaudio' library with the specified version (0.12.0+cu113) from the provided CUDA version repository.\n",
    "!pip install -q torchaudio==0.12.0+cu113 -f https://download.pytorch.org/whl/cu113/torch_stable.html\n",
    "\n",
    "# Add the 'ffmpeg4' repository to the package manager's sources list (-y for yes).\n",
    "!add-apt-repository -y ppa:savoury1/ffmpeg4 \n",
    "\n",
    "# Install the 'ffmpeg' package quietly (-qq).\n",
    "!apt-get -qq install -y ffmpeg\n",
    "\n",
    "# Install the 'mlflow' library quietly (-q).\n",
    "!pip install -q mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T19:36:11.542079Z",
     "iopub.status.busy": "2023-12-18T19:36:11.541779Z",
     "iopub.status.idle": "2023-12-18T19:36:26.255711Z",
     "shell.execute_reply": "2023-12-18T19:36:26.254939Z",
     "shell.execute_reply.started": "2023-12-18T19:36:11.542052Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd  # Pandas for data manipulation\n",
    "import gc  # Garbage collection module\n",
    "import re  # Regular expressions for text processing\n",
    "import numpy as np  # NumPy for numerical operations\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Import tqdm for progress tracking\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "# Import Path from pathlib for working with file paths\n",
    "from pathlib import Path\n",
    "\n",
    "# Import oversampling and undersampling methods from imblearn\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Import class_weight calculation function from scikit-learn\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Import matplotlib for data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import itertools for working with iterators\n",
    "import itertools\n",
    "\n",
    "# Import various metrics from scikit-learn\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,  # For calculating accuracy\n",
    "    roc_auc_score,   # For ROC AUC score\n",
    "    confusion_matrix,  # For confusion matrix\n",
    "    classification_report,  # For classification report\n",
    "    f1_score  # For F1 score\n",
    ")\n",
    "\n",
    "# Import PyTorch for deep learning\n",
    "import torch\n",
    "\n",
    "# Import the Hugging Face Transformers library\n",
    "import transformers\n",
    "\n",
    "# Print the version of the transformers library\n",
    "print(transformers.__version__)\n",
    "\n",
    "# Import torchaudio for audio processing with PyTorch\n",
    "import torchaudio\n",
    "\n",
    "# Print the version of torchaudio\n",
    "print(torchaudio.__version__)\n",
    "\n",
    "# Import a custom module named 'evaluate' for evaluation functions\n",
    "import evaluate\n",
    "\n",
    "# Import Audio for displaying audio clips in the notebook\n",
    "from IPython.display import Audio\n",
    "\n",
    "# Import various classes and modules from Hugging Face Transformers and Datasets\n",
    "from transformers import AutoFeatureExtractor, AutoModelForAudioClassification, pipeline, TrainingArguments, Trainer\n",
    "from datasets import Dataset, Image, ClassLabel  # Import custom 'Dataset', 'ClassLabel', and 'Image' classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T19:36:26.257088Z",
     "iopub.status.busy": "2023-12-18T19:36:26.256803Z",
     "iopub.status.idle": "2023-12-18T19:36:26.262059Z",
     "shell.execute_reply": "2023-12-18T19:36:26.261111Z",
     "shell.execute_reply.started": "2023-12-18T19:36:26.257063Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define the resampling rate in Hertz (Hz) for audio data\n",
    "RATE_HZ = 16000\n",
    "\n",
    "# Define the maximum audio interval length to consider in seconds\n",
    "MAX_SECONDS = 1\n",
    "\n",
    "# Calculate the maximum audio interval length in samples by multiplying the rate and seconds\n",
    "MAX_LENGTH = RATE_HZ * MAX_SECONDS\n",
    "\n",
    "# Define the minimum number of records per label required for the dataset\n",
    "MIN_RECORDS_PER_LABEL = 25\n",
    "\n",
    "# Define the fraction of records to be used for testing data\n",
    "TEST_SIZE = 0.1\n",
    "\n",
    "# Ensure that the product of MIN_RECORDS_PER_LABEL and TEST_SIZE is greater than 2\n",
    "# This ensures a sufficient number of samples for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T19:36:26.264794Z",
     "iopub.status.busy": "2023-12-18T19:36:26.264524Z",
     "iopub.status.idle": "2023-12-18T19:36:26.926335Z",
     "shell.execute_reply": "2023-12-18T19:36:26.925399Z",
     "shell.execute_reply.started": "2023-12-18T19:36:26.264767Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df0 = pd.read_csv('/kaggle/input/common-voice/cv-valid-train.csv', usecols=['filename', 'accent'])\n",
    "df1 = pd.read_csv('/kaggle/input/common-voice/cv-valid-dev.csv', usecols=['filename', 'accent'])\n",
    "df2 = pd.read_csv('/kaggle/input/common-voice/cv-valid-test.csv', usecols=['filename', 'accent'])\n",
    "dd = pd.concat([df0, df1, df2], axis=0)\n",
    "dd = dd[~dd['accent'].isnull()].drop_duplicates()\n",
    "print(dd.shape)\n",
    "dd.sample(5).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T19:36:26.928439Z",
     "iopub.status.busy": "2023-12-18T19:36:26.927811Z",
     "iopub.status.idle": "2023-12-18T19:36:26.947162Z",
     "shell.execute_reply": "2023-12-18T19:36:26.946346Z",
     "shell.execute_reply.started": "2023-12-18T19:36:26.928392Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dd['accent'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T19:36:26.948587Z",
     "iopub.status.busy": "2023-12-18T19:36:26.948258Z",
     "iopub.status.idle": "2023-12-18T19:36:26.956813Z",
     "shell.execute_reply": "2023-12-18T19:36:26.956039Z",
     "shell.execute_reply.started": "2023-12-18T19:36:26.948552Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define a function to load bird sound data from a specified directory.\n",
    "def load_data():\n",
    "    # Initialize empty lists to store file paths and corresponding labels.\n",
    "    file_list = []  # To store file paths\n",
    "    full_list = []  # To store labels\n",
    "\n",
    "    # Iterate through all the .mp3 files in the specified directory and its subdirectories.\n",
    "    for file in tqdm(Path('/kaggle/input/common-voice/').glob('cv-valid-*/*/*.mp3')):\n",
    "        # Extract the label from the file path by splitting the path and retrieving the second-to-last part.\n",
    "        # The label is assumed to be the second-to-last part, separated by '/' and '_' characters.\n",
    "        full_path = str(file)\n",
    "        file_name = '/'.join(str(file).split('/')[-2:])\n",
    "        # Append the current file path to the file_list and its corresponding label to the label_list.\n",
    "        file_list.append(file_name)\n",
    "        full_list.append(full_path)\n",
    "\n",
    "    # Create an empty DataFrame to organize the data.\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    # Create two columns in the DataFrame: 'file' to store file paths and 'label' to store labels.\n",
    "    df['filename'] = file_list\n",
    "    df['file'] = full_list\n",
    "\n",
    "    # Return the DataFrame containing the file paths and labels.\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T19:36:26.958300Z",
     "iopub.status.busy": "2023-12-18T19:36:26.958036Z",
     "iopub.status.idle": "2023-12-18T19:36:31.076019Z",
     "shell.execute_reply": "2023-12-18T19:36:31.075138Z",
     "shell.execute_reply.started": "2023-12-18T19:36:26.958277Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df = load_data()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T19:36:31.077561Z",
     "iopub.status.busy": "2023-12-18T19:36:31.077197Z",
     "iopub.status.idle": "2023-12-18T19:36:31.246261Z",
     "shell.execute_reply": "2023-12-18T19:36:31.245278Z",
     "shell.execute_reply.started": "2023-12-18T19:36:31.077524Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# merge dataframes to get the label\n",
    "df = df.merge(dd, on='filename', how='inner')\n",
    "df.rename(columns={'accent': 'label'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T19:36:31.247909Z",
     "iopub.status.busy": "2023-12-18T19:36:31.247620Z",
     "iopub.status.idle": "2023-12-18T19:36:31.266063Z",
     "shell.execute_reply": "2023-12-18T19:36:31.265147Z",
     "shell.execute_reply.started": "2023-12-18T19:36:31.247884Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df.sample(5).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T19:36:31.270422Z",
     "iopub.status.busy": "2023-12-18T19:36:31.270103Z",
     "iopub.status.idle": "2023-12-18T19:36:31.289199Z",
     "shell.execute_reply": "2023-12-18T19:36:31.288238Z",
     "shell.execute_reply.started": "2023-12-18T19:36:31.270395Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "labels = [lang for lang, _ in Counter(df['label']).most_common(5)]\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T19:36:31.290587Z",
     "iopub.status.busy": "2023-12-18T19:36:31.290282Z",
     "iopub.status.idle": "2023-12-18T19:36:31.312376Z",
     "shell.execute_reply": "2023-12-18T19:36:31.311421Z",
     "shell.execute_reply.started": "2023-12-18T19:36:31.290561Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df = df[df['label'].isin(labels)]\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T19:36:31.314022Z",
     "iopub.status.busy": "2023-12-18T19:36:31.313737Z",
     "iopub.status.idle": "2023-12-18T19:36:31.325443Z",
     "shell.execute_reply": "2023-12-18T19:36:31.324542Z",
     "shell.execute_reply.started": "2023-12-18T19:36:31.313996Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Retrieve unique values in the 'label' column of the DataFrame 'df'\n",
    "unique_labels = df['label'].unique()\n",
    "unique_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T19:36:31.326955Z",
     "iopub.status.busy": "2023-12-18T19:36:31.326619Z",
     "iopub.status.idle": "2023-12-18T19:36:32.082811Z",
     "shell.execute_reply": "2023-12-18T19:36:32.081721Z",
     "shell.execute_reply.started": "2023-12-18T19:36:31.326922Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# random undersampling of a majority class\n",
    "rus = RandomUnderSampler(random_state=83, sampling_strategy='majority')\n",
    "y = df[['label']]\n",
    "df = df.drop(['label'], axis=1)\n",
    "df, y_resampled = rus.fit_resample(df, y)\n",
    "del y\n",
    "df['label'] = y_resampled\n",
    "del y_resampled\n",
    "# # random oversampling of all minority classes\n",
    "# y = df[['label']]\n",
    "# df = df.drop(['label'], axis=1)\n",
    "# ros = RandomOverSampler(random_state=83)\n",
    "# df, y_resampled = ros.fit_resample(df, y)\n",
    "# del y\n",
    "# df['label'] = y_resampled\n",
    "# del y_resampled\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T19:36:32.084927Z",
     "iopub.status.busy": "2023-12-18T19:36:32.084478Z",
     "iopub.status.idle": "2023-12-18T19:54:18.704352Z",
     "shell.execute_reply": "2023-12-18T19:54:18.703375Z",
     "shell.execute_reply.started": "2023-12-18T19:36:32.084886Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# # This function takes a file path as input and performs several audio transformations.\n",
    "# def get_transform_audio(file):\n",
    "#     try:\n",
    "#         # Load the audio file using torchaudio and get its sample rate.\n",
    "#         audio, rate = torchaudio.load(str(file))\n",
    "        \n",
    "#         # Create a transformation to resample the audio to a specified sample rate (RATE_HZ).\n",
    "#         transform = torchaudio.transforms.Resample(rate, RATE_HZ)\n",
    "        \n",
    "#         # Apply the resampling transformation to the audio and convert it to a NumPy array.\n",
    "#         audio = transform(audio).squeeze(0).numpy().reshape(-1)\n",
    "        \n",
    "#         # Truncate the audio to the first MAX_LENGTH samples to save memory.\n",
    "#         audio = audio[:MAX_LENGTH]\n",
    "        \n",
    "#         # Return the preprocessed audio data.\n",
    "#         return audio\n",
    "#     except:\n",
    "#         # If an exception occurs (e.g., file not found), return None.\n",
    "#         return None\n",
    "\n",
    "# # Apply the 'get_transform_audio' function to each file path in the 'df' DataFrame\n",
    "# # and store the preprocessed audio in a new 'audio' column.\n",
    "# df['audio'] = df['file'].progress_apply(get_transform_audio)\n",
    "\n",
    "# Split files by chunks with == MAX_LENGTH size\n",
    "def split_audio(file):\n",
    "    try:\n",
    "        # Load the audio file using torchaudio and get its sample rate.\n",
    "        audio, rate = torchaudio.load(str(file))\n",
    "\n",
    "        # Calculate the number of segments based on the MAX_LENGTH\n",
    "        num_segments = (len(audio[0]) // MAX_LENGTH)  # Floor division to get segments\n",
    "\n",
    "        # Create an empty list to store segmented audio data\n",
    "        segmented_audio = []\n",
    "\n",
    "        # Split the audio into segments\n",
    "        for i in range(num_segments):\n",
    "            start = i * MAX_LENGTH\n",
    "            end = min((i + 1) * MAX_LENGTH, len(audio[0]))\n",
    "            segment = audio[0][start:end]\n",
    "\n",
    "            # Create a transformation to resample the audio to a specified sample rate (RATE_HZ).\n",
    "            transform = torchaudio.transforms.Resample(rate, RATE_HZ)\n",
    "            segment = transform(segment).squeeze(0).numpy().reshape(-1)\n",
    "\n",
    "            segmented_audio.append(segment)\n",
    "\n",
    "        # Create a DataFrame from the segmented audio\n",
    "        df_segments = pd.DataFrame({'audio': segmented_audio})\n",
    "\n",
    "        return df_segments\n",
    "\n",
    "    except Exception as e:\n",
    "        # If an exception occurs (e.g., file not found), return nothing\n",
    "        print(f\"Error processing file: {e}\")\n",
    "        return None\n",
    "    \n",
    "df_list = []\n",
    "for input_file, input_label in tqdm(zip(df['file'].values, df['label'].values)):\n",
    "    resulting_df = split_audio(input_file)\n",
    "    if resulting_df is not None:\n",
    "        resulting_df['label'] = input_label\n",
    "        df_list.append(resulting_df)\n",
    "df = pd.concat(df_list, axis=0)\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T19:54:18.705891Z",
     "iopub.status.busy": "2023-12-18T19:54:18.705636Z",
     "iopub.status.idle": "2023-12-18T19:54:19.610859Z",
     "shell.execute_reply": "2023-12-18T19:54:19.609806Z",
     "shell.execute_reply.started": "2023-12-18T19:54:18.705869Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "del df_list\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T19:54:19.634634Z",
     "iopub.status.busy": "2023-12-18T19:54:19.634312Z",
     "iopub.status.idle": "2023-12-18T19:54:19.726323Z",
     "shell.execute_reply": "2023-12-18T19:54:19.725397Z",
     "shell.execute_reply.started": "2023-12-18T19:54:19.634607Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Selecting rows in the DataFrame where the 'audio' column is not null (contains non-missing values).\n",
    "df = df[~df['audio'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T19:54:19.727792Z",
     "iopub.status.busy": "2023-12-18T19:54:19.727513Z",
     "iopub.status.idle": "2023-12-18T19:54:19.981566Z",
     "shell.execute_reply": "2023-12-18T19:54:19.980443Z",
     "shell.execute_reply.started": "2023-12-18T19:54:19.727768Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T19:54:19.983028Z",
     "iopub.status.busy": "2023-12-18T19:54:19.982736Z",
     "iopub.status.idle": "2023-12-18T19:54:19.987524Z",
     "shell.execute_reply": "2023-12-18T19:54:19.986612Z",
     "shell.execute_reply.started": "2023-12-18T19:54:19.982992Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Removing the 'file' column from the DataFrame 'df'\n",
    "if 'file' in df.columns:\n",
    "    df = df.drop(['file'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T19:54:19.989060Z",
     "iopub.status.busy": "2023-12-18T19:54:19.988777Z",
     "iopub.status.idle": "2023-12-18T19:54:20.643374Z",
     "shell.execute_reply": "2023-12-18T19:54:20.642422Z",
     "shell.execute_reply.started": "2023-12-18T19:54:19.989036Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Identify the unique classes in the training data.\n",
    "classes = np.unique(df[['label']])\n",
    "\n",
    "print(classes)\n",
    "\n",
    "# Calculate class weights using the 'balanced' option, which automatically adjusts for class imbalance.\n",
    "weights = compute_class_weight(class_weight='balanced', classes=classes, y=df['label'])\n",
    "\n",
    "# Create a dictionary mapping each class to its respective class weight.\n",
    "class_weights = dict(zip(classes, weights))\n",
    "\n",
    "# Print the computed class weights to the console.\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T19:54:20.645002Z",
     "iopub.status.busy": "2023-12-18T19:54:20.644696Z",
     "iopub.status.idle": "2023-12-18T19:54:59.343918Z",
     "shell.execute_reply": "2023-12-18T19:54:59.342852Z",
     "shell.execute_reply.started": "2023-12-18T19:54:20.644974Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create a dataset from the Pandas DataFrame 'df'\n",
    "dataset = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T19:54:59.345439Z",
     "iopub.status.busy": "2023-12-18T19:54:59.345153Z",
     "iopub.status.idle": "2023-12-18T19:55:00.443871Z",
     "shell.execute_reply": "2023-12-18T19:55:00.442924Z",
     "shell.execute_reply.started": "2023-12-18T19:54:59.345414Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create a list of unique labels\n",
    "labels_list = ['us', 'england', 'indian', 'australia', 'canada'] #sorted(list(df['label'].unique()))\n",
    "\n",
    "# Deleting the DataFrame 'df'\n",
    "del df\n",
    "\n",
    "# Performing garbage collection to free up memory\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T19:55:00.445650Z",
     "iopub.status.busy": "2023-12-18T19:55:00.445275Z",
     "iopub.status.idle": "2023-12-18T19:55:00.455204Z",
     "shell.execute_reply": "2023-12-18T19:55:00.454182Z",
     "shell.execute_reply.started": "2023-12-18T19:55:00.445615Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Initialize empty dictionaries to map labels to IDs and vice versa\n",
    "label2id, id2label = dict(), dict()\n",
    "\n",
    "# Iterate over the unique labels and assign each label an ID, and vice versa\n",
    "for i, label in enumerate(labels_list):\n",
    "    label2id[label] = i  # Map the label to its corresponding ID\n",
    "    id2label[i] = label  # Map the ID to its corresponding label\n",
    "\n",
    "# Print the resulting dictionaries for reference\n",
    "print(\"Mapping of IDs to Labels:\", id2label, '\\n')\n",
    "print(\"Mapping of Labels to IDs:\", label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T19:55:00.456643Z",
     "iopub.status.busy": "2023-12-18T19:55:00.456367Z",
     "iopub.status.idle": "2023-12-18T19:55:31.171660Z",
     "shell.execute_reply": "2023-12-18T19:55:31.170674Z",
     "shell.execute_reply.started": "2023-12-18T19:55:00.456619Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Creating classlabels to match labels to IDs\n",
    "ClassLabels = ClassLabel(num_classes=len(labels_list), names=labels_list)\n",
    "\n",
    "# Mapping labels to IDs\n",
    "def map_label2id(example):\n",
    "    example['label'] = ClassLabels.str2int(example['label'])\n",
    "    return example\n",
    "\n",
    "dataset = dataset.map(map_label2id, batched=True)\n",
    "\n",
    "# Casting label column to ClassLabel Object\n",
    "dataset = dataset.cast_column('label', ClassLabels)\n",
    "\n",
    "# Splitting the dataset into training and testing sets using the predefined train/test split ratio.\n",
    "dataset = dataset.train_test_split(test_size=TEST_SIZE, shuffle=True, stratify_by_column=\"label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load facebook/wav2vec2-base-960h model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T19:55:31.173410Z",
     "iopub.status.busy": "2023-12-18T19:55:31.173116Z",
     "iopub.status.idle": "2023-12-18T19:55:34.493985Z",
     "shell.execute_reply": "2023-12-18T19:55:34.493020Z",
     "shell.execute_reply.started": "2023-12-18T19:55:31.173383Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoFeatureExtractor, AutoModelForAudioClassification\n",
    "\n",
    "model_str = \"dima806/english_accents_classification\" #\"facebook/wav2vec2-base-960h\" \n",
    "feature_extractor=AutoFeatureExtractor.from_pretrained(model_str)\n",
    "model=AutoModelForAudioClassification.from_pretrained(model_str,num_labels=len(labels))\n",
    "model.config.id2label = id2label\n",
    "# number of trainable parameters\n",
    "print(model.num_parameters(only_trainable=True)/1e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T19:55:34.496454Z",
     "iopub.status.busy": "2023-12-18T19:55:34.495322Z",
     "iopub.status.idle": "2023-12-18T20:24:31.220338Z",
     "shell.execute_reply": "2023-12-18T20:24:31.219362Z",
     "shell.execute_reply.started": "2023-12-18T19:55:34.496412Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def preprocess_function(batch):    \n",
    "    inputs = feature_extractor(batch['audio'], sampling_rate=RATE_HZ, max_length=MAX_LENGTH, truncation=True)\n",
    "    inputs['input_values'] = inputs['input_values'][0]\n",
    "    return inputs\n",
    "\n",
    "dataset['train'] = dataset['train'].map(preprocess_function, remove_columns=\"audio\", batched=False)\n",
    "gc.collect()\n",
    "dataset['test'] = dataset['test'].map(preprocess_function, remove_columns=\"audio\", batched=False)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T20:24:31.222188Z",
     "iopub.status.busy": "2023-12-18T20:24:31.221802Z",
     "iopub.status.idle": "2023-12-18T20:24:32.000079Z",
     "shell.execute_reply": "2023-12-18T20:24:31.999157Z",
     "shell.execute_reply.started": "2023-12-18T20:24:31.222153Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "def compute_metrics(eval_pred):\n",
    "    # Compute the ROC AUC score\n",
    "    predictions = eval_pred.predictions\n",
    "    predictions = np.exp(predictions)/np.exp(predictions).sum(axis=1, keepdims=True)\n",
    "    label_ids = eval_pred.label_ids\n",
    "    roc_auc = roc_auc_score(label_ids, predictions, average='macro', multi_class='ovr')\n",
    "    \n",
    "    # Calculate accuracy using the loaded accuracy metric\n",
    "    acc_score = accuracy.compute(predictions=predictions.argmax(axis=1), references=label_ids)['accuracy']\n",
    "    \n",
    "    return {\n",
    "        \"roc_auc\": roc_auc,\n",
    "        \"accuracy\": acc_score\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T20:24:32.001634Z",
     "iopub.status.busy": "2023-12-18T20:24:32.001321Z",
     "iopub.status.idle": "2023-12-18T20:24:37.676849Z",
     "shell.execute_reply": "2023-12-18T20:24:37.676048Z",
     "shell.execute_reply.started": "2023-12-18T20:24:32.001606Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "batch_size=8\n",
    "warmup_steps=50\n",
    "weight_decay=0.02\n",
    "num_train_epochs=1\n",
    "model_name = \"english_accents_classification\"\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=model_name,\n",
    "    logging_dir='./logs',\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    learning_rate=1e-6, # 3e-5\n",
    "    logging_strategy='steps',\n",
    "    logging_first_step=True,\n",
    "    load_best_model_at_end=True,\n",
    "    logging_steps=1,\n",
    "    evaluation_strategy='epoch',\n",
    "    warmup_steps=warmup_steps,\n",
    "    weight_decay=weight_decay,\n",
    "    eval_steps=1,\n",
    "    gradient_accumulation_steps=1, \n",
    "    gradient_checkpointing=True,\n",
    "    save_strategy='epoch',\n",
    "    save_total_limit=1, # save fewer checkpoints to limit used space\n",
    "    report_to=\"mlflow\",  # log to mlflow\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"test\"],\n",
    "    tokenizer=feature_extractor,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T20:24:37.683508Z",
     "iopub.status.busy": "2023-12-18T20:24:37.683223Z",
     "iopub.status.idle": "2023-12-18T20:28:22.500382Z",
     "shell.execute_reply": "2023-12-18T20:28:22.499434Z",
     "shell.execute_reply.started": "2023-12-18T20:24:37.683473Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T20:28:22.501816Z",
     "iopub.status.busy": "2023-12-18T20:28:22.501527Z",
     "iopub.status.idle": "2023-12-18T21:58:08.837647Z",
     "shell.execute_reply": "2023-12-18T21:58:08.836696Z",
     "shell.execute_reply.started": "2023-12-18T20:28:22.501791Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T21:58:08.839399Z",
     "iopub.status.busy": "2023-12-18T21:58:08.839040Z",
     "iopub.status.idle": "2023-12-18T22:01:45.888041Z",
     "shell.execute_reply": "2023-12-18T22:01:45.886932Z",
     "shell.execute_reply.started": "2023-12-18T21:58:08.839365Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T22:01:45.889679Z",
     "iopub.status.busy": "2023-12-18T22:01:45.889333Z",
     "iopub.status.idle": "2023-12-18T22:05:28.962636Z",
     "shell.execute_reply": "2023-12-18T22:05:28.961716Z",
     "shell.execute_reply.started": "2023-12-18T22:01:45.889651Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Use the trained 'trainer' to make predictions on the test dataset.\n",
    "outputs = trainer.predict(dataset[\"test\"])\n",
    "\n",
    "# Print the metrics obtained from the prediction outputs.\n",
    "print(outputs.metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T22:05:28.964249Z",
     "iopub.status.busy": "2023-12-18T22:05:28.963954Z",
     "iopub.status.idle": "2023-12-18T22:05:29.496802Z",
     "shell.execute_reply": "2023-12-18T22:05:29.495822Z",
     "shell.execute_reply.started": "2023-12-18T22:05:28.964223Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Extract the true labels from the model outputs\n",
    "y_true = outputs.label_ids\n",
    "\n",
    "# Predict the labels by selecting the class with the highest probability\n",
    "y_pred = outputs.predictions.argmax(1)\n",
    "\n",
    "# Define a function to plot a confusion matrix\n",
    "def plot_confusion_matrix(cm, classes, title='Confusion Matrix', cmap=plt.cm.Blues, figsize=(10, 8), is_norm=True):\n",
    "    \"\"\"\n",
    "    This function plots a confusion matrix.\n",
    "\n",
    "    Parameters:\n",
    "        cm (array-like): Confusion matrix as returned by sklearn.metrics.confusion_matrix.\n",
    "        classes (list): List of class names, e.g., ['Class 0', 'Class 1'].\n",
    "        title (str): Title for the plot.\n",
    "        cmap (matplotlib colormap): Colormap for the plot.\n",
    "    \"\"\"\n",
    "    # Create a figure with a specified size\n",
    "    plt.figure(figsize=figsize)\n",
    "    \n",
    "    \n",
    "    # Display the confusion matrix as an image with a colormap\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    # Define tick marks and labels for the classes on the axes\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    \n",
    "    if is_norm:\n",
    "        fmt = '.3f'\n",
    "    else:\n",
    "        fmt = '.0f'\n",
    "    # Add text annotations to the plot indicating the values in the cells\n",
    "    thresh = cm.max() / 2.0\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    # Label the axes\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "    # Ensure the plot layout is tight\n",
    "    plt.tight_layout()\n",
    "    # Display the plot\n",
    "    plt.show()\n",
    "\n",
    "# Calculate accuracy and F1 score\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "# Display accuracy and F1 score\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "# Get the confusion matrix if there are a relatively small number of labels\n",
    "if len(labels) <= 120:\n",
    "    # Compute the confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred) # normalize='true'\n",
    "\n",
    "    # Plot the confusion matrix using the defined function\n",
    "    plot_confusion_matrix(cm, labels, figsize=(8, 6), is_norm=False)\n",
    "\n",
    "# Finally, display classification report\n",
    "print()\n",
    "print(\"Classification report:\")\n",
    "print()\n",
    "print(classification_report(y_true, y_pred, target_names=labels, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T22:05:29.498285Z",
     "iopub.status.busy": "2023-12-18T22:05:29.497967Z",
     "iopub.status.idle": "2023-12-18T22:05:30.041786Z",
     "shell.execute_reply": "2023-12-18T22:05:30.040785Z",
     "shell.execute_reply.started": "2023-12-18T22:05:29.498257Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T22:05:30.043995Z",
     "iopub.status.busy": "2023-12-18T22:05:30.043165Z",
     "iopub.status.idle": "2023-12-18T22:05:31.155778Z",
     "shell.execute_reply": "2023-12-18T22:05:31.154997Z",
     "shell.execute_reply.started": "2023-12-18T22:05:30.043955Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe=pipeline('audio-classification',model=model_name,device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T22:05:31.157437Z",
     "iopub.status.busy": "2023-12-18T22:05:31.157081Z",
     "iopub.status.idle": "2023-12-18T22:05:31.342659Z",
     "shell.execute_reply": "2023-12-18T22:05:31.341731Z",
     "shell.execute_reply.started": "2023-12-18T22:05:31.157403Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# us example\n",
    "audio,rate=torchaudio.load('/kaggle/input/common-voice/cv-valid-test/cv-valid-test/sample-000003.mp3')\n",
    "transform=torchaudio.transforms.Resample(rate,RATE_HZ)\n",
    "audio=transform(audio).numpy().reshape(-1)\n",
    "# make a classification pipeline\n",
    "pipe(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T22:05:31.344403Z",
     "iopub.status.busy": "2023-12-18T22:05:31.344038Z",
     "iopub.status.idle": "2023-12-18T22:05:31.364500Z",
     "shell.execute_reply": "2023-12-18T22:05:31.363602Z",
     "shell.execute_reply.started": "2023-12-18T22:05:31.344369Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "Audio(audio,rate=RATE_HZ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T22:05:31.365787Z",
     "iopub.status.busy": "2023-12-18T22:05:31.365524Z",
     "iopub.status.idle": "2023-12-18T22:05:31.412731Z",
     "shell.execute_reply": "2023-12-18T22:05:31.411932Z",
     "shell.execute_reply.started": "2023-12-18T22:05:31.365764Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# england example\n",
    "audio,rate=torchaudio.load('/kaggle/input/common-voice/cv-valid-test/cv-valid-test/sample-000008.mp3')\n",
    "transform=torchaudio.transforms.Resample(rate,RATE_HZ)\n",
    "audio=transform(audio).numpy().reshape(-1)\n",
    "# make a classification pipeline\n",
    "pipe(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T22:05:31.414007Z",
     "iopub.status.busy": "2023-12-18T22:05:31.413741Z",
     "iopub.status.idle": "2023-12-18T22:05:31.425426Z",
     "shell.execute_reply": "2023-12-18T22:05:31.424444Z",
     "shell.execute_reply.started": "2023-12-18T22:05:31.413983Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "Audio(audio,rate=RATE_HZ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T22:05:31.427189Z",
     "iopub.status.busy": "2023-12-18T22:05:31.426855Z",
     "iopub.status.idle": "2023-12-18T22:05:31.467939Z",
     "shell.execute_reply": "2023-12-18T22:05:31.467222Z",
     "shell.execute_reply.started": "2023-12-18T22:05:31.427160Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# indian example\n",
    "audio,rate=torchaudio.load('/kaggle/input/common-voice/cv-valid-test/cv-valid-test/sample-000033.mp3')\n",
    "transform=torchaudio.transforms.Resample(rate,RATE_HZ)\n",
    "audio=transform(audio).numpy().reshape(-1)\n",
    "# make a classification pipeline\n",
    "pipe(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T22:05:31.469064Z",
     "iopub.status.busy": "2023-12-18T22:05:31.468829Z",
     "iopub.status.idle": "2023-12-18T22:05:31.479260Z",
     "shell.execute_reply": "2023-12-18T22:05:31.478370Z",
     "shell.execute_reply.started": "2023-12-18T22:05:31.469043Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "Audio(audio,rate=RATE_HZ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T22:05:31.480678Z",
     "iopub.status.busy": "2023-12-18T22:05:31.480386Z",
     "iopub.status.idle": "2023-12-18T22:05:31.519353Z",
     "shell.execute_reply": "2023-12-18T22:05:31.518510Z",
     "shell.execute_reply.started": "2023-12-18T22:05:31.480655Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# australia example\n",
    "audio,rate=torchaudio.load('/kaggle/input/common-voice/cv-valid-test/cv-valid-test/sample-000065.mp3')\n",
    "transform=torchaudio.transforms.Resample(rate,RATE_HZ)\n",
    "audio=transform(audio).numpy().reshape(-1)\n",
    "# make a classification pipeline\n",
    "pipe(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T22:05:31.520568Z",
     "iopub.status.busy": "2023-12-18T22:05:31.520281Z",
     "iopub.status.idle": "2023-12-18T22:05:31.529615Z",
     "shell.execute_reply": "2023-12-18T22:05:31.528689Z",
     "shell.execute_reply.started": "2023-12-18T22:05:31.520544Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "Audio(audio,rate=RATE_HZ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T22:05:31.531349Z",
     "iopub.status.busy": "2023-12-18T22:05:31.530824Z",
     "iopub.status.idle": "2023-12-18T22:05:31.566439Z",
     "shell.execute_reply": "2023-12-18T22:05:31.565650Z",
     "shell.execute_reply.started": "2023-12-18T22:05:31.531318Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# canada example\n",
    "audio,rate=torchaudio.load('/kaggle/input/common-voice/cv-valid-test/cv-valid-test/sample-000037.mp3')\n",
    "transform=torchaudio.transforms.Resample(rate,RATE_HZ)\n",
    "audio=transform(audio).numpy().reshape(-1)\n",
    "# make a classification pipeline\n",
    "pipe(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T22:05:31.567823Z",
     "iopub.status.busy": "2023-12-18T22:05:31.567507Z",
     "iopub.status.idle": "2023-12-18T22:05:31.576797Z",
     "shell.execute_reply": "2023-12-18T22:05:31.575906Z",
     "shell.execute_reply.started": "2023-12-18T22:05:31.567792Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "Audio(audio,rate=RATE_HZ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Send model to Huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T22:06:37.750647Z",
     "iopub.status.busy": "2023-12-18T22:06:37.749904Z",
     "iopub.status.idle": "2023-12-18T22:06:37.783848Z",
     "shell.execute_reply": "2023-12-18T22:06:37.782974Z",
     "shell.execute_reply.started": "2023-12-18T22:06:37.750609Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# finally, save the model to Huggingface\n",
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T22:06:52.263680Z",
     "iopub.status.busy": "2023-12-18T22:06:52.263042Z",
     "iopub.status.idle": "2023-12-18T22:06:52.363294Z",
     "shell.execute_reply": "2023-12-18T22:06:52.362446Z",
     "shell.execute_reply.started": "2023-12-18T22:06:52.263643Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi\n",
    "api = HfApi()\n",
    "repo_id = f\"dima806/{model_name}\"\n",
    "try:\n",
    "    api.create_repo(repo_id)\n",
    "except:\n",
    "    print(f\"Repo {repo_id} already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T22:06:53.675849Z",
     "iopub.status.busy": "2023-12-18T22:06:53.675473Z",
     "iopub.status.idle": "2023-12-18T22:07:25.002713Z",
     "shell.execute_reply": "2023-12-18T22:07:25.001676Z",
     "shell.execute_reply.started": "2023-12-18T22:06:53.675818Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "api.upload_folder(\n",
    "    folder_path=model_name,\n",
    "    path_in_repo = \".\",\n",
    "    repo_id=repo_id,\n",
    "    repo_type=\"model\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5793,
     "sourceId": 9812,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30528,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
